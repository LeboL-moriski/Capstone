{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# QCTO - Workplace Module\n",
    "\n",
    "### Project Title: Please Insert your Project Title Here\n",
    "#### Done By: Lebogang Letsoalo\n",
    "\n",
    "© ExploreAI 2024\n",
    "\n",
    "---\n",
    "\n",
    "## Table of Contents\n",
    "\n",
    "<a href=#BC> Background Context</a>\n",
    "\n",
    "<a href=#one>1. Importing Packages</a>\n",
    "\n",
    "<a href=#two>2. Data Collection and Description</a>\n",
    "\n",
    "<a href=#three>3. Loading Data </a>\n",
    "\n",
    "<a href=#four>4. Data Cleaning and Filtering</a>\n",
    "\n",
    "<a href=#five>5. Exploratory Data Analysis (EDA)</a>\n",
    "\n",
    "<a href=#six>6. Modeling </a>\n",
    "\n",
    "<a href=#seven>7. Evaluation and Validation</a>\n",
    "\n",
    "<a href=#eight>8. Final Model</a>\n",
    "\n",
    "<a href=#nine>9. Conclusion and Future Work</a>\n",
    "\n",
    "<a href=#ten>10. References</a>\n",
    "\n",
    "<a href=#Eleven>11. Trello and Github link</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<center><img src=https://media.istockphoto.com/id/1390096829/photo/environment-engineer-collect-samples-of-wastewater-from-industrial-canals-in-test-tube-close.jpg?s=2048x2048&w=is&k=20&c=Cf_1pRlXeFtnAPwiQGbgWFHdBjYXwgp8qDPa_EI31nk= width=\"500\" height=\"100\"></center>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import display, HTML, Image\n",
    "\n",
    "# Display the image in the center of the notebook\n",
    "display(HTML('<center><img src=https://media.istockphoto.com/id/1390096829/photo/environment-engineer-collect-samples-of-wastewater-from-industrial-canals-in-test-tube-close.jpg?s=2048x2048&w=is&k=20&c=Cf_1pRlXeFtnAPwiQGbgWFHdBjYXwgp8qDPa_EI31nk= width=\"500\" height=\"100\"></center>'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    " <a id=\"BC\"></a>\n",
    "## **Background Context**\n",
    "<a href=#cont>Back to Table of Contents</a>\n",
    "\n",
    "* **Purpose:**\n",
    "The purpose of this project is to analyze the physico-chemical parameters of a polluted river located in Buenos Aires, with a focus on identifying trends, correlations, and potential health or environmental risks. The project aims to utilize data collected from various sampling points to better understand the pollution levels and their impacts on water quality.\n",
    "  \n",
    "* **Introduce:**\n",
    "Water pollution is a significant environmental issue in many urban areas, including Buenos Aires, where industrial, agricultural, and domestic activities contribute to the contamination of nearby rivers. The physico-chemical parameters of river water, such as temperature, pH, electrical conductivity (EC), total dissolved solids (TDS), and total suspended solids (TSS), provide vital information about the water quality and its suitability for human consumption, aquatic life, and ecological health. By examining these parameters over time and across different locations, this project seeks to uncover patterns of contamination and inform potential mitigation strategies.\n",
    "\n",
    "* **Objectives:**\n",
    "Data exploration and cleaning: Data Exploration and Cleaning: Organize and clean the data, addressing any missing values or inconsistencies to ensure accurate analysis.\n",
    "Trend Analysis: Analyze how key physico-chemical parameters such as pH, electrical conductivity, total dissolved solids, and total suspended solids change over time and across different sampling locations.\n",
    "Correlation Study: Identify relationships between different environmental variables (e.g., temperature, humidity, and pH) and how they influence the river's contamination levels.\n",
    "Predictive Modeling: Build models to predict water quality based on various environmental factors and sampling data.\n",
    "Recommendations for Environmental Management: Provide actionable insights and recommendations for improving water quality, including identifying critical pollution sources and suggesting mitigation measures."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "<a href=#one></a>\n",
    "## **Importing Packages**\n",
    "<a href=#cont>Back to Table of Contents</a>\n",
    "\n",
    "* **Purpose:** Set up the Python environment with necessary libraries and tools.\n",
    "* **Details:** List and import all the Python packages that will be used throughout the project such as Pandas for data manipulation, Matplotlib/Seaborn for visualization, scikit-learn for modeling, etc.\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Please use code cells to code in and do not forget to comment your code.\n",
    "# Libraries for data loading, manipulation and analysis\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import csv\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "\n",
    "import plotly.express as px\n",
    "import scipy\n",
    "import winsound # -- Used specifically to notify when hour-long code finishes xD "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "<a href=#two></a>\n",
    "## **Data Collection and Description**\n",
    "<a href=#cont>Back to Table of Contents</a>\n",
    "\n",
    "* **Purpose:** Describe how the data was collected and provide an overview of its characteristics.\n",
    "* **Details:** Mention sources of the data, the methods used for collection (e.g., APIs, web scraping, datasets from repositories), and a general description of the dataset including size, scope, and types of data available (e.g., numerical, categorical).\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Project Details: Contaminated River Water Parameters Analysis\r\n",
    "\r\n",
    "#### Dataset Overview\r\n",
    "The dataset used for this analysis was sourced from Kaggle and is the result of a collaborative research effort by three university researchers from Argentina. The research team collected water samples from a widely known polluted river located in Buenos Aires. These samples were taken from various sampling points along the river, including **Puente_Bilbao**, **Puente_Irigoyen**, and **Puente_Falbo**, and analyzed in a chemistry laboratory to measure several physico-chemical parametenent.\r\n",
    "\r\n",
    "The dataset has the following structure:\r\n",
    "\r\n",
    "- **Columns**: 32\r\n",
    "  - **Decimal values**: 14 columns (representing numerical values like temperature, pH, EC, TDS, and TSS).\r\n",
    "  - **Integer values**: 10 columns (representing variables like time, sample counts, or other measurements).\r\n",
    "  - **String values**: 6 columns (including sampling point names and other categorical data).\r\n",
    "\r\n",
    "The data is **chronologically sorted**, ensuring that the time sequence of the samples is preserved. This enables the identification of trends and variations over time, which is crucial for analyzing changes in water quality and the impac of pollution.\r\n",
    "\r\n",
    "#### Sampling Points\r\n",
    "The dataset includes water samples collected from three key sampling points located along the river:\r\n",
    "- **Puente_Bilbao**\r\n",
    "- **Puente_Irigoyen**Arroyo_Las Torres and Arroyo_Salguero are sampling points of 2 different streams flowing into the river.\n",
    "ewater quality in the river."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "<a href=#three></a>\n",
    "## **Loading Data**\n",
    "<a href=#cont>Back to Table of Contents</a>\n",
    "\n",
    "* **Purpose:** Load the data into the notebook for manipulation and analysis.\n",
    "* **Details:** Show the code used to load the data and display the first few rows to give a sense of what the raw data looks like.\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reading the data\n",
    "df = pd.read_csv('archive/River_water parameters.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date (DD/MM/YYYY)</th>\n",
       "      <th>Time (24 hrs XX:XX)</th>\n",
       "      <th>Sampling point</th>\n",
       "      <th>Ambient temperature (°C)</th>\n",
       "      <th>Ambient humidity</th>\n",
       "      <th>Sample temperature (°C)</th>\n",
       "      <th>pH</th>\n",
       "      <th>EC\\n(µS/cm)</th>\n",
       "      <th>TDS\\n(mg/L)</th>\n",
       "      <th>TSS\\n(mL sed/L)</th>\n",
       "      <th>DO\\n(mg/L)</th>\n",
       "      <th>Level (cm)</th>\n",
       "      <th>Turbidity (NTU)</th>\n",
       "      <th>Hardness\\n(mg CaCO3/L)</th>\n",
       "      <th>Hardness classification</th>\n",
       "      <th>Total Cl-\\n(mg Cl-/L)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>09/05/2023</td>\n",
       "      <td>14:15</td>\n",
       "      <td>Puente Bilbao</td>\n",
       "      <td>17.0</td>\n",
       "      <td>0.47</td>\n",
       "      <td>19.0</td>\n",
       "      <td>8.3</td>\n",
       "      <td>1630</td>\n",
       "      <td>810</td>\n",
       "      <td>1.8</td>\n",
       "      <td>4.30</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>147.0</td>\n",
       "      <td>BLANDA</td>\n",
       "      <td>156.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>14/06/2023</td>\n",
       "      <td>14:30</td>\n",
       "      <td>Puente Bilbao</td>\n",
       "      <td>11.9</td>\n",
       "      <td>0.47</td>\n",
       "      <td>13.0</td>\n",
       "      <td>8.1</td>\n",
       "      <td>1000</td>\n",
       "      <td>490</td>\n",
       "      <td>18.0</td>\n",
       "      <td>5.30</td>\n",
       "      <td>NaN</td>\n",
       "      <td>41.2</td>\n",
       "      <td>94.0</td>\n",
       "      <td>BLANDA</td>\n",
       "      <td>78.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>14/06/2023</td>\n",
       "      <td>14:30</td>\n",
       "      <td>Puente Bilbao</td>\n",
       "      <td>11.9</td>\n",
       "      <td>0.47</td>\n",
       "      <td>13.0</td>\n",
       "      <td>8.2</td>\n",
       "      <td>1000</td>\n",
       "      <td>490</td>\n",
       "      <td>18.0</td>\n",
       "      <td>4.67</td>\n",
       "      <td>NaN</td>\n",
       "      <td>38.9</td>\n",
       "      <td>86.0</td>\n",
       "      <td>BLANDA</td>\n",
       "      <td>82.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>14/06/2023</td>\n",
       "      <td>15:00</td>\n",
       "      <td>Arroyo_Las Torres</td>\n",
       "      <td>11.9</td>\n",
       "      <td>0.47</td>\n",
       "      <td>13.0</td>\n",
       "      <td>8.3</td>\n",
       "      <td>1350</td>\n",
       "      <td>670</td>\n",
       "      <td>0.1</td>\n",
       "      <td>7.01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>30.7</td>\n",
       "      <td>200.0</td>\n",
       "      <td>SEMIDURA</td>\n",
       "      <td>117.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>14/06/2023</td>\n",
       "      <td>15:00</td>\n",
       "      <td>Arroyo_Las Torres</td>\n",
       "      <td>11.9</td>\n",
       "      <td>0.47</td>\n",
       "      <td>13.0</td>\n",
       "      <td>8.5</td>\n",
       "      <td>1350</td>\n",
       "      <td>660</td>\n",
       "      <td>0.1</td>\n",
       "      <td>7.23</td>\n",
       "      <td>NaN</td>\n",
       "      <td>25.6</td>\n",
       "      <td>196.0</td>\n",
       "      <td>SEMIDURA</td>\n",
       "      <td>117.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Date (DD/MM/YYYY) Time (24 hrs XX:XX)     Sampling point  \\\n",
       "0        09/05/2023               14:15      Puente Bilbao   \n",
       "1        14/06/2023               14:30      Puente Bilbao   \n",
       "2        14/06/2023               14:30      Puente Bilbao   \n",
       "3        14/06/2023               15:00  Arroyo_Las Torres   \n",
       "4        14/06/2023               15:00  Arroyo_Las Torres   \n",
       "\n",
       "   Ambient temperature (°C)  Ambient humidity  Sample temperature (°C)   pH  \\\n",
       "0                      17.0              0.47                     19.0  8.3   \n",
       "1                      11.9              0.47                     13.0  8.1   \n",
       "2                      11.9              0.47                     13.0  8.2   \n",
       "3                      11.9              0.47                     13.0  8.3   \n",
       "4                      11.9              0.47                     13.0  8.5   \n",
       "\n",
       "   EC\\n(µS/cm)  TDS\\n(mg/L)  TSS\\n(mL sed/L)  DO\\n(mg/L)  Level (cm)  \\\n",
       "0         1630          810              1.8        4.30         NaN   \n",
       "1         1000          490             18.0        5.30         NaN   \n",
       "2         1000          490             18.0        4.67         NaN   \n",
       "3         1350          670              0.1        7.01         NaN   \n",
       "4         1350          660              0.1        7.23         NaN   \n",
       "\n",
       "   Turbidity (NTU)  Hardness\\n(mg CaCO3/L) Hardness classification  \\\n",
       "0              NaN                   147.0                  BLANDA   \n",
       "1             41.2                    94.0                  BLANDA   \n",
       "2             38.9                    86.0                  BLANDA   \n",
       "3             30.7                   200.0                SEMIDURA   \n",
       "4             25.6                   196.0                SEMIDURA   \n",
       "\n",
       "   Total Cl-\\n(mg Cl-/L)  \n",
       "0                  156.0  \n",
       "1                   78.0  \n",
       "2                   82.0  \n",
       "3                  117.0  \n",
       "4                  117.0  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Print dataset\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 219 entries, 0 to 218\n",
      "Data columns (total 16 columns):\n",
      " #   Column                    Non-Null Count  Dtype  \n",
      "---  ------                    --------------  -----  \n",
      " 0   Date (DD/MM/YYYY)         219 non-null    object \n",
      " 1   Time (24 hrs XX:XX)       219 non-null    object \n",
      " 2   Sampling point            219 non-null    object \n",
      " 3   Ambient temperature (°C)  219 non-null    float64\n",
      " 4   Ambient humidity          219 non-null    float64\n",
      " 5   Sample temperature (°C)   219 non-null    float64\n",
      " 6   pH                        219 non-null    float64\n",
      " 7   EC\n",
      "(µS/cm)                219 non-null    int64  \n",
      " 8   TDS\n",
      "(mg/L)                219 non-null    int64  \n",
      " 9   TSS\n",
      "(mL sed/L)            213 non-null    float64\n",
      " 10  DO\n",
      "(mg/L)                 219 non-null    float64\n",
      " 11  Level (cm)                180 non-null    float64\n",
      " 12  Turbidity (NTU)           218 non-null    float64\n",
      " 13  Hardness\n",
      "(mg CaCO3/L)     217 non-null    float64\n",
      " 14  Hardness classification   217 non-null    object \n",
      " 15  Total Cl-\n",
      "(mg Cl-/L)      213 non-null    float64\n",
      "dtypes: float64(10), int64(2), object(4)\n",
      "memory usage: 27.5+ KB\n"
     ]
    }
   ],
   "source": [
    "#Print river water parameters dataset\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Date (DD/MM/YYYY)            0\n",
       "Time (24 hrs XX:XX)          0\n",
       "Sampling point               0\n",
       "Ambient temperature (°C)     0\n",
       "Ambient humidity             0\n",
       "Sample temperature (°C)      0\n",
       "pH                           0\n",
       "EC\\n(µS/cm)                  0\n",
       "TDS\\n(mg/L)                  0\n",
       "TSS\\n(mL sed/L)              6\n",
       "DO\\n(mg/L)                   0\n",
       "Level (cm)                  39\n",
       "Turbidity (NTU)              1\n",
       "Hardness\\n(mg CaCO3/L)       2\n",
       "Hardness classification      2\n",
       "Total Cl-\\n(mg Cl-/L)        6\n",
       "dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check for missing values in each row \n",
    "df.isnull().sum()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: [Date (DD/MM/YYYY), Time (24 hrs XX:XX), Sampling point, Ambient temperature (°C), Ambient humidity, Sample temperature (°C), pH, EC\n",
      "(µS/cm), TDS\n",
      "(mg/L), TSS\n",
      "(mL sed/L), DO\n",
      "(mg/L), Level (cm), Turbidity (NTU), Hardness\n",
      "(mg CaCO3/L), Hardness classification, Total Cl-\n",
      "(mg Cl-/L)]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "# Check for duplicate rows\n",
    "duplicates = df[df.duplicated()]\n",
    "print(duplicates.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "<a href=#four></a>\n",
    "## **Data Cleaning and Filtering**\n",
    "<a href=#cont>Back to Table of Contents</a>\n",
    "\n",
    "* **Purpose:** Prepare the data for analysis by cleaning and filtering.\n",
    "* **Details:** Include steps for handling missing values, removing outliers, correcting errors, and possibly reducing the data (filtering based on certain criteria or features).\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping the rows with small missing values\n",
    "df = df.dropna(subset=['Turbidity (NTU)'])\n",
    "df = df.dropna(subset=['Hardness\\n(mg CaCO3/L)'])\n",
    "df = df.dropna(subset=['Hardness classification'])\n",
    "df = df.dropna(subset=['TSS\\n(mL sed/L)'])\n",
    "df = df.dropna(subset=['Total Cl-\\n(mg Cl-/L)'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the mean of the 'Level (cm)' column, ignoring NaN values\n",
    "mean_level = df['Level (cm)'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill NaN values in the 'Level (cm)' column with the calculated mean\n",
    "df['Level (cm)'] = df['Level (cm)'].fillna(mean_level)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Date (DD/MM/YYYY) Time (24 hrs XX:XX)     Sampling point  \\\n",
      "0        14/06/2023               14:30      Puente Bilbao   \n",
      "1        14/06/2023               14:30      Puente Bilbao   \n",
      "2        14/06/2023               15:00  Arroyo_Las Torres   \n",
      "3        14/06/2023               15:00  Arroyo_Las Torres   \n",
      "4        14/06/2023               15:00    Puente Irigoyen   \n",
      "\n",
      "   Ambient temperature (°C)  Ambient humidity  Sample temperature (°C)   pH  \\\n",
      "0                      11.9              0.47                     13.0  8.1   \n",
      "1                      11.9              0.47                     13.0  8.2   \n",
      "2                      11.9              0.47                     13.0  8.3   \n",
      "3                      11.9              0.47                     13.0  8.5   \n",
      "4                      11.9              0.47                     13.0  8.2   \n",
      "\n",
      "   EC\\n(µS/cm)  TDS\\n(mg/L)  TSS\\n(mL sed/L)  DO\\n(mg/L)  Level (cm)  \\\n",
      "0         1000          490             18.0        5.30   38.095238   \n",
      "1         1000          490             18.0        4.67   38.095238   \n",
      "2         1350          670              0.1        7.01   38.095238   \n",
      "3         1350          660              0.1        7.23   38.095238   \n",
      "4         1200          590             26.0        5.44   38.095238   \n",
      "\n",
      "   Turbidity (NTU)  Hardness\\n(mg CaCO3/L) Hardness classification  \\\n",
      "0             41.2                    94.0                  BLANDA   \n",
      "1             38.9                    86.0                  BLANDA   \n",
      "2             30.7                   200.0                SEMIDURA   \n",
      "3             25.6                   196.0                SEMIDURA   \n",
      "4             24.6                   151.0                SEMIDURA   \n",
      "\n",
      "   Total Cl-\\n(mg Cl-/L)  \n",
      "0                   78.0  \n",
      "1                   82.0  \n",
      "2                  117.0  \n",
      "3                  117.0  \n",
      "4                  109.0  \n"
     ]
    }
   ],
   "source": [
    "# Remove duplicate rows\n",
    "df_cleaned = df.drop_duplicates()\n",
    "\n",
    "# reset the index after removing duplicates\n",
    "df_cleaned = df_cleaned.reset_index(drop=True)\n",
    "\n",
    "# Print the cleaned DataFrame\n",
    "print(df_cleaned.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 4)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "vectorizer = TfidfVectorizer()\n",
    "X = vectorizer.fit_transform(df_cleaned[['Sampling point','Hardness classification']]) \n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scikit-learn in c:\\users\\lebogang\\anaconda3\\lib\\site-packages (1.4.2)\n",
      "Requirement already satisfied: numpy>=1.19.5 in c:\\users\\lebogang\\anaconda3\\lib\\site-packages (from scikit-learn) (1.26.4)\n",
      "Requirement already satisfied: scipy>=1.6.0 in c:\\users\\lebogang\\anaconda3\\lib\\site-packages (from scikit-learn) (1.13.1)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\lebogang\\anaconda3\\lib\\site-packages (from scikit-learn) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\lebogang\\anaconda3\\lib\\site-packages (from scikit-learn) (2.2.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'labelEncoder' from 'sklearn.preprocessing' (C:\\Users\\Lebogang\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[30], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpreprocessing\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m labelEncoder\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m#sample data: categorical labels\u001b[39;00m\n\u001b[0;32m      3\u001b[0m categorical_cols\u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSampling point\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mHardness classification\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "\u001b[1;31mImportError\u001b[0m: cannot import name 'labelEncoder' from 'sklearn.preprocessing' (C:\\Users\\Lebogang\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\__init__.py)"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import labelEncoder\n",
    "#sample data: categorical labels\n",
    "categorical_cols= ['Sampling point','Hardness classification']\n",
    "#Initialize the LabelEncoder\n",
    "label_encoder= LabelEncoder()\n",
    "# Create a dictionary to store original and encoded labels for each column\n",
    "label_mapping = {}  \n",
    "\n",
    "# 3. Fit and transform the data for each column\n",
    "for col in categorical_cols:\n",
    "    # Fit the encoder to the original labels\n",
    "    label_encoder.fit(df[col])  \n",
    "    # Transform the original labels to encoded labels\n",
    "    df[col + '_encoded'] = label_encoder.transform(df[col])  \n",
    "    \n",
    "    # Store the mapping in the dictionary\n",
    "    label_mapping[col] = dict(zip(label_encoder.classes_, label_encoder.transform(label_encoder.classes_))) \n",
    "\n",
    "# 4. Display the mapping (Original Labels --> Encoded Labels)\n",
    "for column, mapping in label_mapping.items():\n",
    "    print(f\"Mapping for column: {column}\")\n",
    "    for original_label, encoded_label in mapping.items():\n",
    "        print(f\"  '{original_label}' --> {encoded_label}\")\n",
    "    print(\"\\n\")\n",
    "\n",
    "\n",
    "# To see the updated DataFrame with encoded columns, run:\n",
    "# df.head()\n",
    "\n",
    "# 5. Inverse Transform (Encoded Labels --> Original Labels)\n",
    "# (To convert encoded labels back to original labels):\n",
    "# df['Sampling point'] = label_encoder.inverse_transform(df['Sampling point_encoded'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p> As we can see, we retained 100.0% of our data after cleaning it.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "<a href=#five></a>\n",
    "## **Exploratory Data Analysis (EDA)**\n",
    "<a href=#cont>Back to Table of Contents</a>\n",
    "\n",
    "* **Purpose:** Explore and visualize the data to uncover patterns, trends, and relationships.\n",
    "* **Details:** Use statistics and visualizations to explore the data. This may include histograms, box plots, scatter plots, and correlation matrices. Discuss any significant findings.\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Please use code cells to code in and do not forget to comment your code."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "<a href=#six></a>\n",
    "## **Modeling**\n",
    "<a href=#cont>Back to Table of Contents</a>\n",
    "\n",
    "* **Purpose:** Develop and train predictive or statistical models.\n",
    "* **Details:** Describe the choice of models, feature selection and engineering processes, and show how the models are trained. Include code for setting up the models and explanations of the model parameters.\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Please use code cells to code in and do not forget to comment your code."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "<a href=#seven></a>\n",
    "## **Evaluation and Validation**\n",
    "<a href=#cont>Back to Table of Contents</a>\n",
    "\n",
    "* **Purpose:** Evaluate and validate the effectiveness and accuracy of the models.\n",
    "* **Details:** Present metrics used to evaluate the models, such as accuracy, precision, recall, F1-score, etc. Discuss validation techniques employed, such as cross-validation or train/test split.\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Please use code cells to code in and do not forget to comment your code."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "<a href=#eight></a>\n",
    "## **Final Model**\n",
    "<a href=#cont>Back to Table of Contents</a>\n",
    "\n",
    "* **Purpose:** Present the final model and its performance.\n",
    "* **Details:** Highlight the best-performing model and discuss its configuration, performance, and why it was chosen over others.\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Please use code cells to code in and do not forget to comment your code."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "<a href=#nine></a>\n",
    "## **Conclusion and Future Work**\n",
    "<a href=#cont>Back to Table of Contents</a>\n",
    "\n",
    "* **Purpose:** Summarize the findings and discuss future directions.\n",
    "* **Details:** Conclude with a summary of the results, insights gained, limitations of the study, and suggestions for future projects or improvements in methodology or data collection.\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Please use code cells to code in and do not forget to comment your code."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "<a href=#ten></a>\n",
    "## **References**\n",
    "<a href=#cont>Back to Table of Contents</a>\n",
    "\n",
    "* **Purpose:** Provide citations and sources of external content.\n",
    "* **Details:** List all the references and sources consulted during the project, including data sources, research papers, and documentation for tools and libraries used.\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Please use code cells to code in and do not forget to comment your code."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Additional Sections to Consider\n",
    "\n",
    "* ### Appendix: \n",
    "For any additional code, detailed tables, or extended data visualizations that are supplementary to the main content.\n",
    "\n",
    "* ### Contributors: \n",
    "If this is a group project, list the contributors and their roles or contributions to the project.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "<a href=#ten></a>\n",
    "## **Trello and Github**\n",
    "<a href=#cont>Back to Table of Contents</a>\n",
    "\n",
    "* **Trello:** https://trello.com/invite/b/67d7e7772b2861f27da83c33/ATTId86647883132da6673d4daf07089d5c1ED99E4A1/workplaceproject\n",
    "* **Github:** https://github.com/LeboL-moriski/Capstone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
